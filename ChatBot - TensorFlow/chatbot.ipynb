{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import config\n",
    "from model_utils import Chatbot\n",
    "from cornell_data_utils import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define get_accuracy helper function to check accuracy of the sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(target, logits):\n",
    "    \"\"\"\n",
    "    Calculate accuracy\n",
    "    \"\"\"\n",
    "    max_seq = max(target.shape[1], logits.shape[1])\n",
    "    if max_seq - target.shape[1]:\n",
    "        target = np.pad(\n",
    "            target,\n",
    "            [(0,0),(0,max_seq - target.shape[1])],\n",
    "            'constant')\n",
    "    if max_seq - logits.shape[1]:\n",
    "        logits = np.pad(\n",
    "            logits,\n",
    "            [(0,0),(0,max_seq - logits.shape[1])],\n",
    "            'constant')\n",
    "\n",
    "    return np.mean(np.equal(target, logits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_questions, cleaned_answers = clean_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating vocab and necessary dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, word_to_id, id_to_word = create_vocab(cleaned_questions, cleaned_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_questions = encoder(cleaned_questions, word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_answers = encoder(cleaned_answers, word_to_id, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucketting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketed_data = bucket_data(encoded_questions, encoded_answers, word_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating model object, session and defining model saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chatbot(config.LEARNING_RATE, \n",
    "                config.BATCH_SIZE, \n",
    "                config.ENCODING_EMBED_SIZE, \n",
    "                config.DECODING_EMBED_SIZE, \n",
    "                config.RNN_SIZE, \n",
    "                config.NUM_LAYERS,\n",
    "                len(vocab), \n",
    "                word_to_id, \n",
    "                config.CLIP_RATE) #4=clip_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(max_to_keep=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entering big buckets, training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(config.EPOCHS):\n",
    "    epoch_accuracy = []\n",
    "    epoch_loss = []\n",
    "    for b in range(len(bucketed_data)):\n",
    "        bucket = bucketed_data[b]\n",
    "        questions_bucket = []\n",
    "        answers_bucket = []\n",
    "        bucket_accuracy = []\n",
    "        bucket_loss = []\n",
    "        for k in range(len(bucket)):\n",
    "            questions_bucket.append(np.array(bucket[k][0]))\n",
    "            answers_bucket.append(np.array(bucket[k][1]))\n",
    "            \n",
    "        for ii in tqdm(range(len(questions_bucket) //  config.BATCH_SIZE)):\n",
    "            \n",
    "            starting_id = ii * config.BATCH_SIZE\n",
    "            \n",
    "            X_batch = questions_bucket[starting_id:starting_id+config.BATCH_SIZE]\n",
    "            y_batch = answers_bucket[starting_id:starting_id+config.BATCH_SIZE]\n",
    "            \n",
    "            feed_dict = {model.inputs:X_batch, \n",
    "                         model.targets:y_batch, \n",
    "                         model.keep_probs:config.KEEP_PROBS, \n",
    "                         model.decoder_seq_len:[len(y_batch[0])]*config.BATCH_SIZE,\n",
    "                         model.encoder_seq_len:[len(X_batch[0])]*config.BATCH_SIZE}\n",
    "            \n",
    "            cost, _, preds = session.run([model.loss, model.opt, model.predictions], feed_dict=feed_dict)\n",
    "            \n",
    "            epoch_accuracy.append(get_accuracy(np.array(y_batch), np.array(preds)))\n",
    "            bucket_accuracy.append(get_accuracy(np.array(y_batch), np.array(preds)))\n",
    "            \n",
    "            bucket_loss.append(cost)\n",
    "            epoch_loss.append(cost)\n",
    "            \n",
    "        print(\"Bucket {}:\".format(b+1), \n",
    "              \" | Loss: {}\".format(np.mean(bucket_loss)), \n",
    "              \" | Accuracy: {}\".format(np.mean(bucket_accuracy)))\n",
    "        \n",
    "    print(\"EPOCH: {}/{}\".format(i, config.EPOCHS), \n",
    "          \" | Epoch loss: {}\".format(np.mean(epoch_loss)), \n",
    "          \" | Epoch accuracy: {}\".format(np.mean(epoch_accuracy)))\n",
    "    \n",
    "    saver.save(session, \"checkpoint/chatbot_{}.ckpt\".format(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
